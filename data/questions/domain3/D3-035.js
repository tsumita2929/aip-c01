window.DOMAIN3_QUESTIONS = window.DOMAIN3_QUESTIONS || [];
window.DOMAIN3_QUESTIONS.push({
  "id": "D3-035",
  "domain": 3,
  "task": "3.4",
  "skill": "3.4.2",
  "type": "single",
  "difficulty": "hard",
  "question": "ある人材紹介会社が、Amazon Bedrock を使用した採用候補者スクリーニングAIシステムを運用しています。システムは履歴書を分析し、職務要件との適合度スコアを出力します。規制当局から、AIシステムが性別、年齢、民族に基づくバイアスを持たないことを定量的に証明し、個別の判定について説明可能性を担保するよう求められました。また、バイアスが検出された場合に、プロンプトの修正やガードレールの追加で対策を実施し、その効果を検証するプロセスも必要です。最も適切なアプローチはどれですか。",
  "options": [
    {
      "id": "A",
      "text": "Amazon Bedrock のモデル評価機能で、性別・年齢・民族の各属性グループ別に準備した評価データセットを用いて適合度スコアの品質を自動評価し、グループ間の差異を検出する。バイアス検出時はプロンプトを修正してガードレールに公平性フィルターを追加し、同じ評価データセットで再評価を実施して改善効果を定量的に検証する"
    },
    {
      "id": "B",
      "text": "Amazon SageMaker AI Clarify でトレーニングデータのバイアスメトリクス（DPL、CI）とモデル予測のバイアスメトリクス（DI、DPPL）を算出し、SHAP 値で各候補者の適合度スコアへの特徴量影響度を説明する。バイアス検出時はデータの再サンプリングを実施してモデルを再トレーニングし、Clarify で再評価する"
    },
    {
      "id": "C",
      "text": "Amazon Bedrock ガードレールのコンテンツフィルターで差別的表現のブロックしきい値を HIGH に設定し、CloudWatch メトリクスでブロック率を監視する。ブロック率が低下すればバイアスが軽減されたと判断し、月次レポートで規制当局に報告する"
    },
    {
      "id": "D",
      "text": "A/B テストで保護属性の異なる候補者グループに対するスコアの統計的有意差を検定し、p値が0.05以上であればバイアスなしと判断する。Amazon CloudWatch RUM でユーザーの操作パターンを分析し、特定グループへの偏りがないことを確認する"
    }
  ],
  "correctAnswers": [
    "A"
  ],
  "explanation": "Amazon Bedrock のモデル評価機能は、属性グループ別の評価データセットを使用してモデルの応答品質（正確性、関連性、有害性等）をグループ間で比較する自動評価を実施できます。このシステムは Bedrock ベースの LLM アプリケーションであるため、LLM の出力評価に特化したモデル評価機能が最適です。バイアス検出後のプロンプト修正・ガードレール追加・再評価の一連のプロセスにより、改善効果の定量的な検証も可能です。B の SageMaker AI Clarify は表形式データの ML モデルのバイアス検出と説明可能性に優れていますが、Bedrock の LLM が生成するテキストベースの適合度スコアに対して DPL や SHAP 値を直接適用することは困難です。LLM の出力バイアス評価にはモデル評価機能の方が適しています。C のガードレールのコンテンツフィルターは差別的表現の「防止」機能であり、適合度スコアの「公平性評価」とは異なります。ブロック率はバイアスの定量的な指標ではなく、規制当局が求める公平性の証明にはなりません。D の A/B テストと統計検定は一般的なバイアス検出手法ですが、p 値のみではバイアスの種類や原因を特定できず、CloudWatch RUM はユーザー操作の分析であり AI の判定バイアスとは関係がありません。（スキル3.4.2）",
  "optionExplanations": {
    "A": {
      "correct": true,
      "text": "正解です。Bedrock モデル評価で属性グループ別の品質を自動評価し、バイアス検出後のプロンプト修正・ガードレール追加・再評価プロセスにより、バイアスの定量的証明と改善効果の検証を直接満たします。"
    },
    "B": {
      "correct": false,
      "text": "不正解です。SageMaker AI Clarify は表形式データの ML モデルに特化しているものの、Bedrock LLM のテキスト出力に DPL や SHAP を直接適用することは困難であり、LLM ベースのスクリーニングシステムのバイアス評価という要件に最適ではありません。"
    },
    "C": {
      "correct": false,
      "text": "不正解です。ガードレールのコンテンツフィルターは差別的表現の防止機能であるものの、適合度スコアの公平性評価とは異なり、ブロック率はバイアスの定量的指標にならないため、定量的なバイアス証明という要件を満たしません。"
    },
    "D": {
      "correct": false,
      "text": "不正解です。A/B テストの統計検定はバイアス検出の一手法であるものの、p 値のみではバイアスの種類や原因の特定ができず、CloudWatch RUM はユーザー操作分析で AI 判定バイアスとは無関係であるため、包括的なバイアス評価という要件を満たしません。"
    }
  },
  "references": [
    {
      "title": "Amazon Bedrock Model Evaluation",
      "url": "https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation.html"
    },
    {
      "title": "Amazon SageMaker Clarify - Detect Bias",
      "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-detect-data-bias.html"
    }
  ]
});
