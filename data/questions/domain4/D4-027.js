window.DOMAIN4_QUESTIONS = window.DOMAIN4_QUESTIONS || [];
window.DOMAIN4_QUESTIONS.push({
  "id": "D4-027",
  "domain": 4,
  "task": "4.1",
  "skill": "4.1.2",
  "type": "single",
  "difficulty": "hard",
  "question": "ある SaaS 企業が、テナントごとにカスタマイズされた機械学習モデルを Amazon SageMaker でホスティングしています。現在 200 テナント分のモデルがあり、各テナントのトラフィックは不均一で、一部のテナントは1日数回しかリクエストがありません。現在は各モデルに個別のリアルタイムエンドポイントを割り当てていますが、インフラコストが高騰しています。低トラフィックテナントの推論レイテンシを 1 秒以内に維持しながら、インフラコストを大幅に削減する必要があります。最も適切なアプローチはどれですか？",
  "options": [
    {
      "id": "A",
      "text": "すべてのテナントのモデルを1つの SageMaker マルチモデルエンドポイント（MME）に統合し、共有のインスタンス上で動的にモデルをロード・アンロードしてコストを削減する"
    },
    {
      "id": "B",
      "text": "すべてのテナントのモデルを SageMaker Serverless Inference エンドポイントに移行し、リクエストがない間はコストが発生しないようにする"
    },
    {
      "id": "C",
      "text": "低トラフィックテナントのモデルを SageMaker バッチ変換ジョブに移行し、定期的にバッチ処理で推論を実行する"
    },
    {
      "id": "D",
      "text": "低トラフィックテナントのモデルを SageMaker 非同期推論エンドポイントに移行し、リクエストがない間はインスタンスを 0 にスケールダウンする"
    }
  ],
  "correctAnswers": [
    "A"
  ],
  "explanation": "正解はAです。SageMaker マルチモデルエンドポイント（MME）は、複数のモデルを単一のエンドポイント上でホスティングし、リクエストに応じてモデルを動的にロード・アンロードします。200 テナント分のモデルを共有インスタンス上に統合することで、個別エンドポイントと比較してインフラコストを大幅に削減できます。頻繁にアクセスされるモデルはメモリにキャッシュされ、低トラフィックテナントのモデルもリクエスト時にロードされるため、1 秒以内のレイテンシ要件を満たせます。B の Serverless Inference はコールドスタートが発生するため、リクエスト頻度が低いテナントでは毎回コールドスタートが発生し、1 秒以内のレイテンシ要件を安定的に満たすことが困難です。C のバッチ変換はリアルタイム推論ではないため、即座のレスポンスが必要なユースケースには適しません。D の非同期推論は 0 へのスケールダウンが可能ですが、スケールアップ時にインスタンス起動の待機時間が発生し、1 秒以内のレイテンシ要件を満たしません。（スキル: 4.1.2）",
  "optionExplanations": {
    "A": {
      "correct": true,
      "text": "正解です。SageMaker マルチモデルエンドポイントは、200 テナント分のモデルを共有インスタンス上で動的にホスティングすることで、インフラコストの大幅削減と 1 秒以内のレイテンシ維持を直接満たします。特にモデルのキャッシュ機構により、効率的なリソース利用を実現できます。"
    },
    "B": {
      "correct": false,
      "text": "不正解です。Serverless Inference はコスト最適化には有用であるものの、低トラフィックテナントでは毎回コールドスタートが発生するため、1 秒以内のレイテンシという要件を安定的に満たしません。"
    },
    "C": {
      "correct": false,
      "text": "不正解です。バッチ変換はリアルタイム推論ではなく定期的なバッチ処理であるため、即座のレスポンスが必要なユースケースには適さず、レイテンシ要件を満たしません。"
    },
    "D": {
      "correct": false,
      "text": "不正解です。非同期推論の 0 へのスケールダウンはコスト削減に有用であるものの、スケールアップ時にインスタンス起動の待機時間が発生するため、1 秒以内のレイテンシという要件を満たしません。"
    }
  },
  "references": [
    {
      "title": "Amazon SageMaker マルチモデルエンドポイント",
      "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/multi-model-endpoints.html"
    },
    {
      "title": "Amazon SageMaker - 推論オプションの選択",
      "url": "https://docs.aws.amazon.com/sagemaker/latest/dg/deploy-model.html"
    }
  ]
});
